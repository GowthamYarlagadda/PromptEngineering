{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2A7L0RQYV0Q9",
        "outputId": "800c16df-d872-4e1d-e902-b5530f14fde5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.27.8)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import time"
      ],
      "metadata": {
        "id": "d7yJWAqOVug1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "prVvdiMEUlM2"
      },
      "outputs": [],
      "source": [
        "class LLMWrapper:\n",
        "    def __init__(self, api_key, token_limit):\n",
        "        openai.api_key = api_key\n",
        "        self.token_limit = token_limit\n",
        "        self.history = []\n",
        "\n",
        "    def format_prompt(self, prompt, *variables):\n",
        "        formatted_prompt = prompt.format(*variables)\n",
        "        return formatted_prompt\n",
        "\n",
        "    def update_history(self, formatted_prompt):\n",
        "        if len(self.history) + len(formatted_prompt.split()) > self.token_limit:\n",
        "            truncated_history = self.history.copy()\n",
        "            while len(truncated_history) + len(formatted_prompt.split()) > self.token_limit:\n",
        "                removed_prompt = truncated_history.pop(0)\n",
        "                print(f\"Truncating history: {removed_prompt}\")\n",
        "            self.history = truncated_history\n",
        "        self.history.append(formatted_prompt)\n",
        "\n",
        "    def generate_response(self, conversation):\n",
        "        try:\n",
        "            response = openai.Completion.create(\n",
        "                engine=\"text-davinci-003\",\n",
        "                prompt=conversation,\n",
        "                max_tokens=125\n",
        "            )\n",
        "            return response.choices[0].text.strip()\n",
        "        except openai.error.RateLimitError as rate_limit_error:\n",
        "            print(\"Rate limit exceeded. Retrying in 10 seconds...\")\n",
        "            time.sleep(10)  # Retry after a delay\n",
        "            return self.generate_response(conversation)\n",
        "        except openai.error.TooManyRequestsError as token_limit_error:\n",
        "            print(\"Token limit exceeded. Truncating history and retrying...\")\n",
        "            truncated_history = self.history.copy()\n",
        "            while len(truncated_history) + len(conversation.split()) > self.token_limit:\n",
        "                removed_prompt = truncated_history.pop(0)\n",
        "                print(f\"Truncating history: {removed_prompt}\")\n",
        "            return self.generate_response(\"\\n\".join(truncated_history))\n",
        "\n",
        "    def interact(self, user_input, *variables):\n",
        "        formatted_prompt = self.format_prompt(user_input, *variables)\n",
        "        self.update_history(formatted_prompt)\n",
        "        conversation = \"\\n\".join(self.history)\n",
        "        response = self.generate_response(conversation)\n",
        "        return response\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the LLM Wrapper\n",
        "api_key = \"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\"\n",
        "token_limit = 2000\n",
        "llm_wrapper = LLMWrapper(api_key, token_limit)\n",
        "\n",
        "# Initialize conversation variables\n",
        "conversation_history = []\n",
        "\n",
        "# Simulate a Conversation\n",
        "print(\"Bot: Hi there! I'm here to chat. What's your name?\")\n",
        "user_input = input(\"You: \")\n",
        "conversation_history.append(\"You: \" + user_input)\n",
        "\n",
        "response = llm_wrapper.interact(\"\\n\".join(conversation_history))\n",
        "print(\"Bot:\", response)\n",
        "conversation_history.append(\"Bot: \" + response)\n",
        "\n",
        "# Continue the Conversation\n",
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "    conversation_history.append(\"You: \" + user_input)\n",
        "\n",
        "    if \"bye\" in user_input.lower():\n",
        "        print(\"Bot: Goodbye! Have a great day.\")\n",
        "        break\n",
        "\n",
        "    response = llm_wrapper.interact(\"\\n\".join(conversation_history))\n",
        "    print(\"Bot:\", response)\n",
        "    conversation_history.append(\"Bot: \" + response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQBYGvA-ciLd",
        "outputId": "e80c1ea0-2870-4271-de8d-f41ac11bed84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bot: Hi there! I'm here to chat. What's your name?\n",
            "You: gowtham\n",
            "Bot: Bot: Hi Gowtham! It's nice to meet you. How can I help you today?\n",
            "You: Just wanna talk\n",
            "Bot: Bot: Sure thing! What would you like to talk about?\n",
            "You: how to secure a internship in a fast way\n",
            "Bot: ?\n",
            "You: ?\n",
            "Bot: Bot: Bot: Securing an internship in a fast way requires some preparation. Firstly, you should have a good understanding of what type of internship you want and what kind of skills and experience you have to offer. Additionally, itâ€™s important to network with employers and make sure your resume and profile on any sites such as LinkedIn are up to date and showcase your best qualifications. Finally, actively search for internship opportunities and apply for as many as you can.\n",
            "You: I have ML & DL , computer vision and nlp and also DSA in pythom. At present I am learning AWS \n",
            "Bot: Bot: Bot: Great! With the skills that you have listed, you should consider looking into internships related to big data, machine learning, software engineering, and cloud computing. Check if there are any open positions available at the companies you'd like to intern at, or even online internship boards to gain more leads. Additionally, try reaching out to your connections and network to get an introduction. Keep updating your profile on job portals and social media sites, such as LinkedIn, to increase your chance of getting an interview. Good luck!\n",
            "You: thank you but what else should I learn ?\n",
            "Bot: Bot: Bot: It depends on what type of internship you are looking for. For example, if you are looking for a software internship, you may want to focus on learning more development, coding, and software testing skills. Additionally, if you are looking for an internship related to cloud computing, you may want to focus on learning more about cloud platform services such as AWS or Azure.\n",
            "You: Okay bye!\n",
            "Bot: Goodbye! Have a great day.\n"
          ]
        }
      ]
    }
  ]
}